{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088\n",
      "['P6', 'P7', 'P9', 'P10']\n",
      "['head of government', 'brother', 'sister', 'video']\n"
     ]
    }
   ],
   "source": [
    "#Import necessary pkgs \n",
    "import requests#to retrieve data from endpoint\n",
    "import json#to parse .json\n",
    "import pandas as pd#to work with Pandas df\n",
    "\n",
    "#Fetch data with .get form online repo\n",
    "wd_p_raw = requests.get(\"https://raw.githubusercontent.com/molybdenum-99/reality/master/data/wikidata-predicates.json\")\n",
    "print(len(wd_p_raw.json()))\n",
    "#Coverting json to type DataFrame\n",
    "#Extracting key-value pairs as indv observ (field entries)\n",
    "keys = []#initialise am empty list to store dict keys\n",
    "values = []#initialise am empty list to store dict key values\n",
    "for k in wd_p_raw.json():\n",
    "    keys.append(k)\n",
    "print(keys[0:4])#visualising list to confirm\n",
    "for v in  wd_p_raw.json().values():\n",
    "    values.append(v)\n",
    "print(values[0:4])#visualising list to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame contain 2088 entries!\n"
     ]
    }
   ],
   "source": [
    "#Creating the DataFrame\n",
    "df = pd.DataFrame({'p_ids': keys, 'p_labels': values})\n",
    "df.head()#inspect df\n",
    "#import numpy as np\n",
    "print(\"The DataFrame contain\", len(df.index), \"entries!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oface/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_ids</th>\n",
       "      <th>p_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>P769</td>\n",
       "      <td>significant drug interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>P923</td>\n",
       "      <td>medical examinations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>P924</td>\n",
       "      <td>medical treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>P1050</td>\n",
       "      <td>medical condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>P1995</td>\n",
       "      <td>medical specialty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>P2074</td>\n",
       "      <td>internetmedicin.se ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>P2175</td>\n",
       "      <td>medical condition treated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>P2176</td>\n",
       "      <td>drug used for treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_ids                      p_labels\n",
       "549    P769  significant drug interaction\n",
       "688    P923          medical examinations\n",
       "689    P924             medical treatment\n",
       "796   P1050             medical condition\n",
       "1606  P1995             medical specialty\n",
       "1681  P2074         internetmedicin.se ID\n",
       "1778  P2175     medical condition treated\n",
       "1779  P2176       drug used for treatment"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset the df where there are labels with \"drug\" or \"treat\" or \"medic\" pharases\n",
    "df_toi = df[df.p_labels.str.contains(\"[^.!?;]*(drug)[^.!?;]*\") \\\n",
    "            | df.p_labels.str.contains(\"[^.!?;]*(treat)[^.!?;]*\") \\\n",
    "            | df.p_labels.str.contains(\"[^.!?;]*(medic)[^.!?;]*\")]\n",
    "\n",
    "df_toi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ouso'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LastName = 'Ouso'\n",
    "test= {\n",
    "    'FirstName': 'Dan',\n",
    "    'MiddleName': 'Obado',\n",
    "    'LastName': LastName\n",
    "}\n",
    "\n",
    "test['LastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_ids</th>\n",
       "      <th>p_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>P769</td>\n",
       "      <td>significant drug interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>P923</td>\n",
       "      <td>medical examinations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>P924</td>\n",
       "      <td>medical treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>P1050</td>\n",
       "      <td>medical condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>P1995</td>\n",
       "      <td>medical specialty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>P2074</td>\n",
       "      <td>internetmedicin.se ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>P2175</td>\n",
       "      <td>medical condition treated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>P2176</td>\n",
       "      <td>drug used for treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_ids                      p_labels\n",
       "549    P769  significant drug interaction\n",
       "688    P923          medical examinations\n",
       "689    P924             medical treatment\n",
       "796   P1050             medical condition\n",
       "1606  P1995             medical specialty\n",
       "1681  P2074         internetmedicin.se ID\n",
       "1778  P2175     medical condition treated\n",
       "1779  P2176       drug used for treatment"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for (n, m) in zip(df_toi.p_ids, df_toi.p_labels):\n",
    "    zip(df_toi.p_ids, df_toi.p_labels)\n",
    "    name  = n\n",
    "    des = m\n",
    "    #print (name)\n",
    "    #print (des)\n",
    "    print(type(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moleculeLabel</th>\n",
       "      <th>conditionLabel</th>\n",
       "      <th>formule</th>\n",
       "      <th>picture</th>\n",
       "      <th>condition</th>\n",
       "      <th>molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(+)-phenylpropanolamine</td>\n",
       "      <td>common cold</td>\n",
       "      <td>C₉H₁₃NO</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q12125</td>\n",
       "      <td>http://www.wikidata.org/entity/Q413147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(+)-phenylpropanolamine</td>\n",
       "      <td>obesity</td>\n",
       "      <td>C₉H₁₃NO</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q12174</td>\n",
       "      <td>http://www.wikidata.org/entity/Q413147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(+)-phenylpropanolamine</td>\n",
       "      <td>rhinitis</td>\n",
       "      <td>C₉H₁₃NO</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q114085</td>\n",
       "      <td>http://www.wikidata.org/entity/Q413147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(+-)-flurbiprofen</td>\n",
       "      <td>osteoarthritis</td>\n",
       "      <td>C₁₅H₁₃FO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q62736</td>\n",
       "      <td>http://www.wikidata.org/entity/Q419890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(+-)-flurbiprofen</td>\n",
       "      <td>inflammation</td>\n",
       "      <td>C₁₅H₁₃FO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q101991</td>\n",
       "      <td>http://www.wikidata.org/entity/Q419890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             moleculeLabel  conditionLabel    formule  \\\n",
       "0  (+)-phenylpropanolamine     common cold    C₉H₁₃NO   \n",
       "1  (+)-phenylpropanolamine         obesity    C₉H₁₃NO   \n",
       "2  (+)-phenylpropanolamine        rhinitis    C₉H₁₃NO   \n",
       "3        (+-)-flurbiprofen  osteoarthritis  C₁₅H₁₃FO₂   \n",
       "4        (+-)-flurbiprofen    inflammation  C₁₅H₁₃FO₂   \n",
       "\n",
       "                                             picture  \\\n",
       "0  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "1  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "2  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "3  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "4  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "\n",
       "                                condition  \\\n",
       "0   http://www.wikidata.org/entity/Q12125   \n",
       "1   http://www.wikidata.org/entity/Q12174   \n",
       "2  http://www.wikidata.org/entity/Q114085   \n",
       "3   http://www.wikidata.org/entity/Q62736   \n",
       "4  http://www.wikidata.org/entity/Q101991   \n",
       "\n",
       "                                 molecule  \n",
       "0  http://www.wikidata.org/entity/Q413147  \n",
       "1  http://www.wikidata.org/entity/Q413147  \n",
       "2  http://www.wikidata.org/entity/Q413147  \n",
       "3  http://www.wikidata.org/entity/Q419890  \n",
       "4  http://www.wikidata.org/entity/Q419890  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"/home/oface/Documents/Flashpub/wd_meds_cond_query.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moleculeLabel</th>\n",
       "      <th>conditionLabel</th>\n",
       "      <th>formule</th>\n",
       "      <th>picture</th>\n",
       "      <th>condition</th>\n",
       "      <th>molecule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>influenza, severe, susceptibility to</td>\n",
       "      <td>C₈H₉NO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q56003062</td>\n",
       "      <td>http://www.wikidata.org/entity/Q57055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>pain</td>\n",
       "      <td>C₈H₉NO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q81938</td>\n",
       "      <td>http://www.wikidata.org/entity/Q57055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>hyperthermia</td>\n",
       "      <td>C₈H₉NO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q242165</td>\n",
       "      <td>http://www.wikidata.org/entity/Q57055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>nasopharyngitis</td>\n",
       "      <td>C₈H₉NO₂</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q18553870</td>\n",
       "      <td>http://www.wikidata.org/entity/Q57055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     moleculeLabel                        conditionLabel  formule  \\\n",
       "267  acetaminophen  influenza, severe, susceptibility to  C₈H₉NO₂   \n",
       "268  acetaminophen                                  pain  C₈H₉NO₂   \n",
       "269  acetaminophen                          hyperthermia  C₈H₉NO₂   \n",
       "270  acetaminophen                       nasopharyngitis  C₈H₉NO₂   \n",
       "\n",
       "                                               picture  \\\n",
       "267  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "268  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "269  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "270  http://commons.wikimedia.org/wiki/Special:File...   \n",
       "\n",
       "                                    condition  \\\n",
       "267  http://www.wikidata.org/entity/Q56003062   \n",
       "268     http://www.wikidata.org/entity/Q81938   \n",
       "269    http://www.wikidata.org/entity/Q242165   \n",
       "270  http://www.wikidata.org/entity/Q18553870   \n",
       "\n",
       "                                  molecule  \n",
       "267  http://www.wikidata.org/entity/Q57055  \n",
       "268  http://www.wikidata.org/entity/Q57055  \n",
       "269  http://www.wikidata.org/entity/Q57055  \n",
       "270  http://www.wikidata.org/entity/Q57055  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aceta = data[data.moleculeLabel.str.contains('acetaminophen')]\n",
    "aceta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.moleculeLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000-0003-0994-2558'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ousoOrcid = u'0000-0003-0994-2558'\n",
    "ousoOrcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-11-18-14:45:03'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d-%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A toatal of 1  documents have been added to the dictionary in firestore dev on 2019-11-18-14:54:45\n"
     ]
    }
   ],
   "source": [
    "entryCount = 1\n",
    "print('A total of', entryCount, ' documents have been added to the dictionary \\\n",
    "in firestore dev on', datetime.today().strftime('%Y-%m-%d-%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://query.wikidata.org/embed.html#\")\n",
    "type(response)\n",
    "print(response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = open('samplefile.txt', 'a') \n",
    "  \n",
    "print('Ouso', file = sample) \n",
    "#sample.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeeksForGeeks\n",
      "\n",
      "Geeks\n",
      "\n",
      "Ouso\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = open('samplefile.txt', 'r+')\n",
    "for line in sample:\n",
    "    print(line)\n",
    "sample.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "Delete only documents containing `powered by Wikidata` as `origin` from firestore `dictionary` collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndocs = db.collection(u'dictionary').where(u'origin', u'==', u'powered by Wikidata').stream() # Retrieve all docs with filter\\nfor doc in docs: # Iterate through the docs and collect only the IDs and dump them into a file\\n    dict_IDs = open('dict_IDs.txt', 'a')\\n    print(u'{}'.format(doc.id), file = dict_IDs)#, doc.to_dict())) # Getting only the document IDs\\n    dict_IDs.close()\\ndict_IDs = open('dict_IDs.txt', 'r+')\\nfor line in dict_IDs: # Iterate through doc IDs deleting one item at a time\\n    db.collection(u'dictionary').document(line).delete() \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"...\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "'''\n",
    "docs = db.collection(u'dictionary').where(u'origin', u'==', u'powered by Wikidata').stream() # Retrieve all docs with filter\n",
    "for doc in docs: # Iterate through the docs and collect only the IDs and dump them into a file\n",
    "    dict_IDs = open('dict_IDs.txt', 'a')\n",
    "    print(u'{}'.format(doc.id), file = dict_IDs)#, doc.to_dict())) # Getting only the document IDs\n",
    "    dict_IDs.close()\n",
    "dict_IDs = open('dict_IDs.txt', 'r+')\n",
    "for line in dict_IDs: # Iterate through doc IDs deleting one item at a time\n",
    "    db.collection(u'dictionary').document(line).delete() \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_IDs = open('dict_IDs.txt', 'r+')\n",
    "for line in dict_IDs:\n",
    "    #db.collection(u'dictionary').document(line).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type '_io.TextIOWrapper' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d49fc1fcfc84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdict_IDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dict_IDs.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_IDs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_IDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type '_io.TextIOWrapper' has no len()"
     ]
    }
   ],
   "source": [
    "#dict_IDs = open('dict_IDs.txt', 'r+')\n",
    "#for line in dict_IDs:\n",
    "    #print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seconds: 1574282812\n",
       "nanos: 648504000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = '0005a5ac-b91a-4971-931d-ce8079289303'\n",
    "#db.collection(u'dictionary').document(x).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0c35d4a0-9b42-462b-b2fb-321e6e910982 => {'description': 'a type of cancer treatment that uses one or more anti-cancer drugs (chemotherapeutic agents) as part of a standardized chemotherapy regimen.', 'props': {}, 'longName': 'chemotherapy', 'isCommunity': False, 'name': 'chemotherapy', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', 'adabe023-24ec-4a02-892f-8cfdcbc43f30'], 'type': 'thing', 'origin': 'api-python', 'metrics': {'dateAdded': 1572972961000.0, 'pubCount': 2, 'authorCount': 0, 'dateModified': 1572972961000.0}, 'id': '0c35d4a0-9b42-462b-b2fb-321e6e910982', 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}}\n",
      "\n",
      "6055ca7f-3ed7-409a-bab3-0193169fe031 => {'metrics': {'dateModified': 1572972847000.0, 'dateAdded': 1572972847000.0, 'pubCount': 1, 'authorCount': 0}, 'id': '6055ca7f-3ed7-409a-bab3-0193169fe031', 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'props': {}, 'description': 'a rare malignant tumor that commonly develops in the upper nasal cavity.', 'name': 'ENB', 'isCommunity': False, 'longName': 'Esthesioneuroblastoma', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "8414ef6e-59bf-4ec8-b3c9-75588947a21c => {'type': 'thing', 'origin': 'api-python', 'metrics': {'pubCount': 2, 'authorCount': 0, 'dateAdded': 1572973737000.0, 'dateModified': 1572973737000.0}, 'id': '8414ef6e-59bf-4ec8-b3c9-75588947a21c', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'description': 'A cancer of the lymphatic system, particularly B lymphocytes found in the germinal center.', 'props': {}, 'longName': 'Burkitt Lymphoma', 'isCommunity': False, 'name': 'burkittlymphoma', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910']}\n",
      "\n",
      "8810c4ed-1db1-4c85-901b-b6e46966e910 => {'metrics': {'dateAdded': 1571772532000.0, 'pubCount': 2, 'authorCount': 0, 'dateModified': 1571772532000.0}, 'id': '8810c4ed-1db1-4c85-901b-b6e46966e910', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'description': 'Human illnesses', 'props': {}, 'name': 'disease', 'isCommunity': False, 'longName': 'Disease', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135'], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "8cda779e-3e9e-4506-ac43-2ef39551d4e1 => {'metrics': {'dateAdded': 1571954161000.0, 'pubCount': 3, 'authorCount': 0, 'dateModified': 1571954161000.0}, 'id': '8cda779e-3e9e-4506-ac43-2ef39551d4e1', 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'description': 'Bacterial infection typically of the lungs caused by genus species.', 'props': {}, 'longName': 'Tuberculosis', 'name': 'TB', 'isCommunity': False, 'ancestors': ['8810c4ed-1db1-4c85-901b-b6e46966e910', '9f39c304-9c67-4251-83d9-86f7837c0135'], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "9294802b-1cc8-4f9d-ae1e-00f617a42a01 => {'origin': 'api-python', 'metrics': {'dateAdded': 1572307986000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1572307986000.0}, 'id': '9294802b-1cc8-4f9d-ae1e-00f617a42a01', 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'description': 'A medication used to treat pain and fever.', 'props': {}, 'longName': 'acetaminophen', 'name': 'acetaminophen', 'isCommunity': False, 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', 'adabe023-24ec-4a02-892f-8cfdcbc43f30'], 'type': 'thing'}\n",
      "\n",
      "9f39c304-9c67-4251-83d9-86f7837c0135 => {'metrics': {'dateAdded': 1571772472000.0, 'pubCount': 62, 'authorCount': 0, 'dateModified': 1571772472000.0}, 'id': '9f39c304-9c67-4251-83d9-86f7837c0135', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'props': {}, 'description': 'Diagnosis, treatment, and study of human illnesses.', 'longName': 'Clinic', 'isCommunity': True, 'name': 'clinic', 'ancestors': [], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "a270f4ca-bd54-41de-98a4-c68a20fb1c33 => {'metrics': {'dateAdded': 1571772798000.0, 'pubCount': 1, 'authorCount': 0, 'dateModified': 1571772798000.0}, 'id': 'a270f4ca-bd54-41de-98a4-c68a20fb1c33', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'description': 'Any device or process that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.', 'props': {}, 'longName': 'Artificial Intelligence', 'isCommunity': True, 'name': 'ai', 'ancestors': [], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "adabe023-24ec-4a02-892f-8cfdcbc43f30 => {'origin': 'api-python', 'metrics': {'dateAdded': 1571772601000.0, 'pubCount': 1, 'authorCount': 0, 'dateModified': 1571772601000.0}, 'id': 'adabe023-24ec-4a02-892f-8cfdcbc43f30', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'props': {}, 'description': 'Drug, procedure, or therapy to alleviate human illnesses or suffering.', 'isCommunity': False, 'name': 'treatment', 'longName': 'Treatment', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135'], 'type': 'thing'}\n",
      "\n",
      "b6e280c9-63ce-4ea5-829a-b5fc5e5b42a1 => {'metrics': {'pubCount': 6, 'authorCount': 0, 'dateAdded': 1572559075000.0, 'dateModified': 1572559075000.0}, 'id': 'b6e280c9-63ce-4ea5-829a-b5fc5e5b42a1', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-0994-2558'}, 'description': 'Arboviral infection.', 'props': {'vector': 'Mosquitoes', 'organism': 'Virus'}, 'longName': 'Dengue Fever', 'isCommunity': False, 'name': 'dengue', 'ancestors': ['8810c4ed-1db1-4c85-901b-b6e46966e910', '9f39c304-9c67-4251-83d9-86f7837c0135'], 'type': 'thing', 'origin': 'api-python'}\n",
      "\n",
      "cce4e32c-8720-4139-a812-8929008c1b22 => {'type': 'thing', 'origin': 'api-python', 'metrics': {'dateModified': 1571772920000.0, 'dateAdded': 1571772920000.0, 'pubCount': 0, 'authorCount': 0}, 'id': 'cce4e32c-8720-4139-a812-8929008c1b22', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'props': {}, 'description': 'The machine learning task of learning a function that maps an input to an output based on example input-output pairs.', 'name': 'supervisedlearning', 'isCommunity': False, 'longName': 'Supervised Learning', 'ancestors': ['a270f4ca-bd54-41de-98a4-c68a20fb1c33']}\n",
      "\n",
      "db644648-fe8d-4b7a-9eca-bd3cbe0c8c82 => {'type': 'thing', 'origin': 'api-python', 'metrics': {'dateAdded': 1572626578000.0, 'pubCount': 41, 'authorCount': 0, 'dateModified': 1572626578000.0}, 'id': 'db644648-fe8d-4b7a-9eca-bd3cbe0c8c82', 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'description': 'A fast-growing glioma that develops from star-shaped glial cells (astrocytes and oligodendrocytes) that support the health of the nerve cells within the brain.', 'props': {}, 'name': 'GBM', 'isCommunity': False, 'longName': 'Glioblastoma Multiforme', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"....json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "docs = db.collection(u'dictionary').where(u'origin', u'==', u'api-python').stream() # Retrieve all docs with filter\n",
    "for doc in docs: # Iterate through the docs and collect the docs and dump them into a file\n",
    "    dict_docs = open('dict_docs.txt', 'a')\n",
    "    print(u'{} => {}'.format(doc.id, doc.to_dict()), file = dict_docs)#, doc.to_dict())) # Getting only the document IDs\n",
    "    dict_docs.close()\n",
    "dict_docs = open('dict_docs.txt', 'r+')\n",
    "#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\n",
    "for line in dict_docs: # Iterate through doc IDs deleting one item at a time\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21 22:43:10\n",
      "1574365390.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "pythonTime = datetime.now()\n",
    "print(time.mktime(pythonTime.timetuple()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "Retrieve all initial entries from the firestore dict collection and order RESTfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"....json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "docs = db.collection(u'dictionary').stream()#where(u'origin', u'==', u'api-python').stream()\n",
    "\n",
    "keys = ['name', 'longName', 'description', 'ancestors', 'props', 'author', 'type', 'origin', 'id', 'isCommunity', 'metrics']\n",
    "for doc in docs:\n",
    "    new_dict = {}\n",
    "    for k in keys:\n",
    "        new_dict[k]=doc.to_dict().get(k)\n",
    "    init_log_ids = open('init_log_ids.txt', 'a')\n",
    "    init_log_dict = open('init_log_dict.txt', 'a')\n",
    "    print(u'{}'.format(doc.id), file = init_log_ids)\n",
    "    print(u'{}'.format(new_dict), file = init_log_dict)\n",
    "    init_log_ids.close()\n",
    "    init_log_dict.close()\n",
    "\n",
    "#init_log = open('init_log.txt', 'r+')\n",
    "#for line in old_dict_Fs:\n",
    "#    print(line)\n",
    "'''\n",
    "    \n",
    "    #    db.collection(u'dictionary').document(line).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'GBM', 'longName': 'Glioblastoma Multiforme', 'description': 'A fast-growing glioma that develops from star-shaped glial cells (astrocytes and oligodendrocytes) that support the health of the nerve cells within the brain.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'api-python', 'id': 'db644648-fe8d-4b7a-9eca-bd3cbe0c8c82', 'isCommunity': False, 'metrics': {'dateModified': 1572626578000.0, 'dateAdded': 1572626578000.0, 'pubCount': 40, 'authorCount': 0}}\n"
     ]
    }
   ],
   "source": [
    "#doc.to_dict().keys()\n",
    "keys = ['name', 'longName', 'description', 'ancestors', 'props', 'author', 'type', 'origin', 'id', 'isCommunity', 'metrics']\n",
    "new_dict = {}\n",
    "for k in keys:\n",
    "    new_dict[k]=doc.to_dict().get(k)\n",
    "print(new_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crooked way of repoplating the firestore\n",
    "ids = ['0c35d4a0-9b42-462b-b2fb-321e6e910982', '6055ca7f-3ed7-409a-bab3-0193169fe031', '8414ef6e-59bf-4ec8-b3c9-75588947a21c', \\\n",
    "       '8810c4ed-1db1-4c85-901b-b6e46966e910', '8cda779e-3e9e-4506-ac43-2ef39551d4e1', '9294802b-1cc8-4f9d-ae1e-00f617a42a01', \\\n",
    "       '9f39c304-9c67-4251-83d9-86f7837c0135', 'a270f4ca-bd54-41de-98a4-c68a20fb1c33', 'adabe023-24ec-4a02-892f-8cfdcbc43f30', \\\n",
    "       'b6e280c9-63ce-4ea5-829a-b5fc5e5b42a1', 'cce4e32c-8720-4139-a812-8929008c1b22', 'db644648-fe8d-4b7a-9eca-bd3cbe0c8c82', \\\n",
    "       '08073dff-5f68-4e6a-830e-ccb7bbfc8aec', 'a09615d2-4299-4d36-90dd-7648b97589ea']\n",
    "dt = [{'name': 'chemotherapy', 'longName': 'chemotherapy', 'description': 'a type of cancer treatment that uses one or more anti-cancer drugs (chemotherapeutic agents) as part of a standardized chemotherapy regimen.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', 'adabe023-24ec-4a02-892f-8cfdcbc43f30'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'api-python', 'id': '0c35d4a0-9b42-462b-b2fb-321e6e910982', 'isCommunity': False, 'metrics': {'dateAdded': 1572972961000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1572972961000.0}}, {'name': 'ENB', 'longName': 'Esthesioneuroblastoma', 'description': 'a rare malignant tumor that commonly develops in the upper nasal cavity.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'api-python', 'id': '6055ca7f-3ed7-409a-bab3-0193169fe031', 'isCommunity': False, 'metrics': {'dateModified': 1572972847000.0, 'pubCount': 0, 'authorCount': 0, 'dateAdded': 1572972847000.0}}, {'name': 'burkittlymphoma', 'longName': 'Burkitt Lymphoma', 'description': \\\n",
    "'A cancer of the lymphatic system, particularly B lymphocytes found in the germinal center.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'api-python', 'id': '8414ef6e-59bf-4ec8-b3c9-75588947a21c', 'isCommunity': False, 'metrics': {'pubCount': 0, 'authorCount': 0, 'dateAdded': 1572973737000.0, 'dateModified': 1572973737000.0}}, {'name': 'disease', 'longName': 'Disease', 'description': 'Human illnesses', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135'], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'type': 'thing', 'origin': 'api-python', 'id': '8810c4ed-1db1-4c85-901b-b6e46966e910', 'isCommunity': False, 'metrics': {'dateAdded': 1571772532000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1571772532000.0}}, {'name': 'TB', 'longName': 'Tuberculosis', 'description': 'Bacterial infection typically of the lungs caused by genus species.', 'ancestors': ['8810c4ed-1db1-4c85-901b-b6e46966e910', '9f39c304-9c67-4251-83d9-86f7837c0135'], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, \\\n",
    "'type': 'thing', 'origin': 'api-python', 'id': '8cda779e-3e9e-4506-ac43-2ef39551d4e1', 'isCommunity': False, 'metrics': {'pubCount': 0, 'authorCount': 0, 'dateAdded': 1571954161000.0, 'dateModified': 1571954161000.0}}, {'name': 'acetaminophen', 'longName': 'acetaminophen', 'description': 'A medication used to treat pain and fever.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', 'adabe023-24ec-4a02-892f-8cfdcbc43f30'], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'type': 'thing', 'origin': 'api-python', 'id': '9294802b-1cc8-4f9d-ae1e-00f617a42a01', 'isCommunity': False, 'metrics': {'dateAdded': 1572307986000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1572307986000.0}}, {'name': 'clinic', 'longName': 'Clinic', 'description': 'Diagnosis, treatment, and study of human illnesses.', 'ancestors': [], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'type': 'thing', 'origin': 'api-python', 'id': '9f39c304-9c67-4251-83d9-86f7837c0135', 'isCommunity': True, 'metrics': {'pubCount': 0, 'authorCount': 0, 'dateAdded': 1571772472000.0, 'dateModified': 1571772472000.0}}, {'name': 'ai', 'longName': 'Artificial Intelligence', 'description': 'Any \\\n",
    "device or process that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.', 'ancestors': [], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'type': 'thing', 'origin': 'api-python', 'id': 'a270f4ca-bd54-41de-98a4-c68a20fb1c33', 'isCommunity': True, 'metrics': {'dateModified': 1571772798000.0, 'pubCount': 0, 'authorCount': 0, 'dateAdded': 1571772798000.0}}, {'name': 'treatment', 'longName': 'Treatment', 'description': 'Drug, procedure, or therapy to alleviate human illnesses or suffering.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135'], 'props': {}, 'author': {'affiliation': '@flashpub.io', 'orcid': '0000-0003-2175-6627'}, 'type': 'thing', 'origin': 'api-python', 'id': 'adabe023-24ec-4a02-892f-8cfdcbc43f30', 'isCommunity': False, 'metrics': {'pubCount': 0, 'authorCount': 0, 'dateAdded': 1571772601000.0, 'dateModified': 1571772601000.0}}, {'name': 'dengue', 'longName': 'Dengue Fever', 'description': 'Arboviral infection.', 'ancestors': ['8810c4ed-1db1-4c85-901b-b6e46966e910', '9f39c304-9c67-4251-83d9-86f7837c0135'], 'props': {'vector': 'Mosquitoes', 'organism': 'Virus'}, 'author': {'affiliation': '@flashpub.io', 'orcid': \\\n",
    "'0000-0003-0994-2558'}, 'type': 'thing', 'origin': 'api-python', 'id': 'b6e280c9-63ce-4ea5-829a-b5fc5e5b42a1', 'isCommunity': False, 'metrics': {'dateAdded': 1572559075000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1572559075000.0}}, {'name': 'supervisedlearning', 'longName': 'Supervised Learning', 'description': 'The machine learning task of learning a function that maps an input to an output based on example input-output pairs.', 'ancestors': ['a270f4ca-bd54-41de-98a4-c68a20fb1c33'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'api-python', 'id': 'cce4e32c-8720-4139-a812-8929008c1b22', 'isCommunity': False, 'metrics': {'dateModified': 1571772920000.0, 'pubCount': 0, 'authorCount': 0, 'dateAdded': 1571772920000.0}}, {'name': 'GBM', 'longName': 'Glioblastoma Multiforme', 'description': 'A fast-growing glioma that develops from star-shaped glial cells (astrocytes and oligodendrocytes) that support the health of the nerve cells within the brain.', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {}, 'author': {'orcid': '0000-0003-2175-6627', 'affiliation': '@flashpub.io'}, 'type': 'thing', \\\n",
    "'origin': 'api-python', 'id': 'db644648-fe8d-4b7a-9eca-bd3cbe0c8c82', 'isCommunity': False, 'metrics': {'dateAdded': 1572626578000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1572626578000.0}}, {'name': 'ncds', 'longName': 'Noncommunicable Diseases', 'description': 'Diseases that tend to be of long duration and are the result of a combination of genetic, physiological, environmental and behaviours factors', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {'nature': 'chronic'}, 'author': {'orcid': '0000-0003-0994-2558', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'manual', 'id': '08073dff-5f68-4e6a-830e-ccb7bbfc8aec', 'isCommunity': True, 'metrics': {'dateAdded': 1574794813000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1574794813000.0}}, {'name': 'commds', 'longName': 'Communicable Diseases', 'description': 'An infectious disease that is contagious and is transmissible by direct (as by primary physical link) or indirect (as by a vector) contact with an infectious agent or its toxins from a source to another', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {'nature': 'acute'}, \\\n",
    "'author': {'orcid': '0000-0003-0994-2558', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'manual', 'id': 'a09615d2-4299-4d36-90dd-7648b97589ea', 'isCommunity': True, 'metrics': {'dateModified': 1574794640000.0, 'dateAdded': 1574794640000.0, 'pubCount': 0, 'authorCount': 0}}]\n",
    "#for (i, d) in zip(ids, dt):\n",
    "#    db.collection(u'dictionary').document(i).set(d)\n",
    "\n",
    "'''\n",
    "ancestorEntriesIDs = open('ancestorEntriesIDs.txt', 'a'); ancestorEntriesDict = open('ancestorEntriesDict.txt', 'a')\n",
    "[print(IDs, file = ancestorEntriesIDs) for IDs in ids]\n",
    "[print(dicts, file = ancestorEntriesDict) for dicts in dt]\n",
    "ancestorEntriesIDs.close(); ancestorEntriesDict.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>item</th>\n",
       "      <th>formule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ethanol</td>\n",
       "      <td>http://www.wikidata.org/entity/Q153</td>\n",
       "      <td>C₂H₆O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sodium chloride</td>\n",
       "      <td>http://www.wikidata.org/entity/Q2314</td>\n",
       "      <td>NaCl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rabeprazole</td>\n",
       "      <td>http://www.wikidata.org/entity/Q3515</td>\n",
       "      <td>C₁₈H₂₁N₃O₃S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arsenic trioxide</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7739</td>\n",
       "      <td>As₂O₃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adenine</td>\n",
       "      <td>http://www.wikidata.org/entity/Q15277</td>\n",
       "      <td>C₅H₅N₅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          itemLabel                                   item      formule\n",
       "0           ethanol    http://www.wikidata.org/entity/Q153        C₂H₆O\n",
       "1   sodium chloride   http://www.wikidata.org/entity/Q2314         NaCl\n",
       "2       rabeprazole   http://www.wikidata.org/entity/Q3515  C₁₈H₂₁N₃O₃S\n",
       "3  arsenic trioxide   http://www.wikidata.org/entity/Q7739        As₂O₃\n",
       "4           adenine  http://www.wikidata.org/entity/Q15277       C₅H₅N₅"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json(\"/home/oface/Documents/Flashpub/wd_meds_item_id.json\")\n",
    "data_ = data.head()\n",
    "data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem\n",
    "Retrieve the entity id Q* from the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q153', 'Q2314', 'Q3515', 'Q7739', 'Q15277']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = 'http://www.wikidata.org/entity/Q2314'\n",
    "ent_ids = []\n",
    "for x in data.item:\n",
    "    x.split('/')# Slipt using slash as split-point\n",
    "    y = x.split('/')[-1]# Slice the last item in the list\n",
    "    ent_ids.append(y)\n",
    "ent_ids_ = ent_ids[0:5]\n",
    "ent_ids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ids</th>\n",
       "      <th>shortName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethanol</td>\n",
       "      <td>Q153</td>\n",
       "      <td>Ethanol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sodium chloride</td>\n",
       "      <td>Q2314</td>\n",
       "      <td>SodiumChloride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rabeprazole</td>\n",
       "      <td>Q3515</td>\n",
       "      <td>Rabeprazole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenic trioxide</td>\n",
       "      <td>Q7739</td>\n",
       "      <td>ArsenicTrioxide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adenine</td>\n",
       "      <td>Q15277</td>\n",
       "      <td>Adenine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name     ids        shortName\n",
       "0           Ethanol    Q153          Ethanol\n",
       "1   Sodium chloride   Q2314   SodiumChloride\n",
       "2       Rabeprazole   Q3515      Rabeprazole\n",
       "3  Arsenic trioxide   Q7739  ArsenicTrioxide\n",
       "4           Adenine  Q15277          Adenine"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "f = []\n",
    "for h in data_.itemLabel:\n",
    "    z.append(h.capitalize())\n",
    "    f.append(h.title().replace(' ', ''))\n",
    "data_ = pd.DataFrame({'name': z, 'ids': ent_ids_, 'shortName': f})\n",
    "data_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethanol\n",
      "SodiumChloride\n",
      "Rabeprazole\n",
      "ArsenicTrioxide\n",
      "Adenine\n"
     ]
    }
   ],
   "source": [
    "#c = 'Arsenic trioxide'\n",
    "for c in data_.name:\n",
    "    c = c.title().replace(' ', '')\n",
    "    print(c)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305\n",
      "2305\n",
      "2305\n"
     ]
    }
   ],
   "source": [
    "l = []; i = []; n = []; j = []# Initialise empty lists for storing extracted info\n",
    "\n",
    "for (x, z) in zip(data.item, data.itemLabel):# Iterate through the DataFrame using a for loop to retrieve required info\n",
    "    i.append(x.split('/')[-1])# Slipt str using fwd slash as split-point, slice the last item in the list which is the ID string and add to a list\n",
    "    l.append(z.title())# Capitalise drug names and \n",
    "    t = z.replace(' ', '').replace(')', '').replace('(', \\\n",
    "    '').replace('-', '').replace('+', '').replace('[', \\\n",
    "    '').replace(']', '').replace('/', '').lower()# Capitalise @ word in itemLabel then remove spaces - 'hashtagging' and add to a list\n",
    "    j.append(t)\n",
    "#[n.append(i[0].lower() + i[1:]) for i in j]# Lowercase the first letter in list j\n",
    "print(len(i)); print(len(l)); print(len(j))     \n",
    "# Create a new DataFrame with retrieved info    \n",
    "#data_ = pd.DataFrame({'name': n, 'ids': i, 'longName': l})# Create a new DataFrame with the resulting lists above\n",
    "#data_.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('brainCancer.txt', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob('../../**/....json', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "for file in os.listdir('../../anaconda3'):\n",
    "    if fnmatch.fnmatch(file, '../../....json'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08073dff-5f68-4e6a-830e-ccb7bbfc8aec => {'name': 'NCDs', 'longName': 'Noncommunicable Diseases', 'description': 'Diseases that tend to be of long duration and are the result of a combination of genetic, physiological, environmental and behaviours factors', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {'nature': 'chronic'}, 'author': {'orcid': '0000-0003-0994-2558', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'manual', 'id': '08073dff-5f68-4e6a-830e-ccb7bbfc8aec', 'isCommunity': False, 'metrics': {'dateAdded': 1574794813000.0, 'pubCount': 0, 'authorCount': 0, 'dateModified': 1574794813000.0}}\n",
      "\n",
      "a09615d2-4299-4d36-90dd-7648b97589ea => {'name': 'CommDs', 'longName': 'Communicable Diseases', 'description': 'An infectious disease that is contagious and is transmissible by direct (as by primary physical link) or indirect (as by a vector) contact with an infectious agent or its toxins from a source to another', 'ancestors': ['9f39c304-9c67-4251-83d9-86f7837c0135', '8810c4ed-1db1-4c85-901b-b6e46966e910'], 'props': {'nature': 'acute'}, 'author': {'orcid': '0000-0003-0994-2558', 'affiliation': '@flashpub.io'}, 'type': 'thing', 'origin': 'manual', 'id': 'a09615d2-4299-4d36-90dd-7648b97589ea', 'isCommunity': False, 'metrics': {'dateModified': 1574794640000.0, 'dateAdded': 1574794640000.0, 'pubCount': 0, 'authorCount': 0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"....json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "docs = db.collection(u'dictionary').where(u'origin', u'==', u'manual').stream()\n",
    "\n",
    "keys = ['name', 'longName', 'description', 'ancestors', 'props', 'author', 'type', 'origin', 'id', 'isCommunity', 'metrics']\n",
    "for doc in docs:\n",
    "    new_dict = {}\n",
    "    for k in keys:\n",
    "        new_dict[k]=doc.to_dict().get(k)\n",
    "    old_dict_FsII = open('old_dict_FsII.txt', 'a')\n",
    "    print(u'{} => {}'.format(doc.id, new_dict), file = old_dict_FsII)\n",
    "    old_dict_FsII.close()\n",
    "old_dict_FsII = open('old_dict_FsII.txt', 'r+')\n",
    "for line in old_dict_FsII:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0:00:00.000087\n",
      "A toatal of braincancer items have been added to the dictionary in firestore dev on 2019-11-28-23:32:53 in time 0:00:00.000087\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()#.strftime('%H:%M:%S')\n",
    "start\n",
    "duration = datetime.now() - start\n",
    "print('took', duration)\n",
    "# IMPORT_NEEDED_PKGs\n",
    "print('A toatal of braincancer items have been added to the dictionary \\\n",
    "in firestore dev on', datetime.today().strftime('%Y-%m-%d-%H:%M:%S'), 'in time', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doud**__='"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function for removing meta-characters from strings\n",
    "v = 'doud  **(__+=)'\n",
    "#v.replace(('(', '*', '_'), '')\n",
    "v\n",
    "\n",
    "def rm_metaxters_fp(s):\n",
    "    if s:\n",
    "        t = s.replace(' ', '').replace(')', '').replace('(', \\\n",
    "        '').replace('-', '').replace('+', '').replace('[', '').replace(']', '').replace('/', '')\n",
    "        return t\n",
    "rm_metaxters_fp(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doud**ouso__='"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v = 'doud  **OUSO(__+=)/[]'\n",
    "t = v.replace(' ', '').replace(')', '').replace('(', \\\n",
    "    '').replace('-', '').replace('+', '').replace('[', \\\n",
    "    '').replace(']', '').replace('/', '').lower()# Capitalise @ word in itemLabel then remove spaces - 'hashtagging' and add to a list\n",
    "    #j.append(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESS_DATA\n",
    "l = []; i = []; n = []; j = []# Initialise empty lists for storing extracted info\n",
    "\n",
    "for (x, z) in zip(wikiData.item, wikiData.itemLabel):# Iterate through the DataFrame using a for loop to retrieve required info\n",
    "    i.append(x.split('/')[-1])# Slipt str using fwd slash as split-point, slice the last item in the list which is the ID string and add to a list\n",
    "    l.append(z.capitalize())# Capitalise drug names and \n",
    "    j.append(z.title().replace(' ', ''))# Capitalise @ word in itemLabel then remove spaces - 'hashtagging' and add to a list\n",
    "[n.append(i[0].lower() + i[1:]) for i in j]# Lowercase the first letter in list j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2f89db7d8ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OusoLionRoof'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#os.path.realpath(__file__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('../../firebase-o.json')\n",
    "os.path.basename('../../firebase-o.json')\n",
    "os.path.dirname('firebase-o.json')\n",
    "os.path.realpath('OusoLionRoof')\n",
    "#os.path.realpath(__file__)\n",
    "os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-66ae9bf9e48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "h, g = open('h.txt', 'g.txt', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESS_SPARQL_ENDPOINT\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = '''\n",
    "SELECT ?item ?itemLabel #?cancer ?subclass #?symptomLabel  ?symptom\n",
    "WHERE\n",
    "{\n",
    "\t?item  wdt:P279  wd:Q18554460#wd:Q12078#(cancer) Q29512471(cancertypes)   #Q6608753(listofcancertypes)\n",
    "    #; wdt:P31 ?subclass\n",
    "\tSERVICE wikibase:label {  bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "ORDER BY ?itemLabel\n",
    "'''\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    sparql = SPARQLWrapper(endpoint_url, user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)    \n",
    "# CONVERT_TO_FLASHPUB_DATA_MODEL\n",
    "def to_fp_data_model(d):\n",
    "    import pandas as pd, requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    i = []; l = []; s = []; u = []; x = []# Initialise empty lists for storing extracted info\n",
    "    for item in d[\"results\"][\"bindings\"]:\n",
    "        v = BeautifulSoup(requests.get(item['item']['value']).text, features = 'lxml').find('span', class_='wikibase-descriptionview-text')\n",
    "        j = item['item']['value'].split('/')[-1] # qid\n",
    "        m = item['itemLabel']['value'].title() # longName\n",
    "        t = m.replace(' ', '').replace(')', '').replace('(', \\\n",
    "        '').replace('-', '').replace('.', '').replace(',', \\\n",
    "        '').replace(\"'\", '').replace(\"'\", '').lower() #shortName\n",
    "        i.append(j); l.append(m); s.append(t); u.append(v); x.append(w)\n",
    "        #print(j, m, t)\n",
    "    return pd.DataFrame({'name': s, 'ids': i, 'longName': l, 'description': x, 'url': u})# Create a new DataFrame with the resulting lists above fs-firestore\n",
    "print(to_fp_data_model(results))\n",
    "#v = item['item']['value']\n",
    "#print(type(v))\n",
    "'''\n",
    "import requests\n",
    "qid_lnk = requests.get('https://www.wikidata.org/wiki/Q290805')\n",
    "print(qid_lnk.status_code)\n",
    "#print(qid_lnk.text)\n",
    "soup = BeautifulSoup(qid_lnk.text, 'lxml')\n",
    "description = soup.find('span', class_='wikibase-descriptionview-text').text.lower()\n",
    "print(description)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q474254'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Bannayan-Riley-Ruvalcaba syndrome'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q3377927'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'PHACE association'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1047551'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Pinealoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q281115'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Proteus syndrome'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1886238'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Sturge–Weber syndrome'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q631904'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'atypical teratoid rhabdoid tumor'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q55789755'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'brain astrocytoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18555001'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'brain germinoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18553667'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'brain glioma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18553665'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'brain meningioma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18555002'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'brain sarcoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18556218'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'cerebral neuroblastoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18557623'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'childhood central nervous system mixed germ cell tumor'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18557585'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'childhood germ cell brain tumor'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18556934'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'extragonadal nonseminomatous germ cell tumor'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1531482'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'gliomatosis cerebri'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q55780322'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'hereditary neurocutaneous malformation'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18556009'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'hypothalamic neoplasm'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18556448'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'infratentorial cancer'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q19001372'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'malignant neoplasm of cerebrum except lobes and ventricles'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18556013'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'olfactory nerve neoplasm'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18557522'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'pediatric CNS embryonal cell carcinoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q2095252'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'pilocytic astrocytoma'}}\n",
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q18554868'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'supratentorial cancer'}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"#added before 2016-10\n",
    "\n",
    "SELECT ?item ?itemLabel #?cancer ?subclass #?symptomLabel  ?symptom\n",
    "WHERE\n",
    "{\n",
    "\t?item  wdt:P279  wd:Q18554460#wd:Q12078#(cancer) Q29512471(cancertypes)   #Q6608753(listofcancertypes)\n",
    "    #; wdt:P31 ?subclass\n",
    "\tSERVICE wikibase:label {  bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "ORDER BY ?itemLabel\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "r = requests.get('http://www.wikidata.org/entity/Q55505')\n",
    "w = BeautifulSoup(r.text, 'lxml')\n",
    "z = w.find('span', class_='wikibase-descriptionview-text')\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: `None output`\n",
    "## Compare upper and lower cell: the `URL` difference at `entity` causes the `None` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "no description defined\n"
     ]
    }
   ],
   "source": [
    "qid_lnk = requests.get('https://www.wikidata.org/wiki/Q290805')\n",
    "print(qid_lnk.status_code)\n",
    "#print(qid_lnk.text)\n",
    "soup = BeautifulSoup(qid_lnk.text, 'lxml')\n",
    "description = soup.find('span', class_='wikibase-descriptionview-text').text.lower()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "## apply `replace()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wikidata.org/wiki/Q290805\n"
     ]
    }
   ],
   "source": [
    "j = 'https://www.wikidata.org/entity/Q290805'\n",
    "h = j.replace('entity', 'wiki')\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Eclapsia\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "replace() argument 1 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-863a814ca4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
     ]
    }
   ],
   "source": [
    "bx = 'Pre-eclapsia'\n",
    "\n",
    "print(bx.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, XML, JSON, N3\n",
    "from rdflib import Graph\n",
    "\n",
    "#Select query\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?label, ?comment\n",
    "    WHERE { <http://dbpedia.org/resource/Biology> rdfs:comment ?comment}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"comment\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESS_SPARQL_ENDPOINT\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = '''\n",
    "SELECT ?itemLabel ?item\n",
    "WHERE\n",
    "{\n",
    "\t?item  wdt:P279  wd:Q5526839\n",
    "\tSERVICE wikibase:label {  bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "ORDER BY ?itemLabel\n",
    "'''\n",
    "\n",
    "\n",
    "def get_results(x, y):\n",
    "    sparql = SPARQLWrapper(x)\n",
    "    sparql.setQuery(y)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "print(results)\n",
    "\n",
    "'''\n",
    "# CONVERT_TO_FLASHPUB_DATA_MODEL\n",
    "def to_fp_data_model(d):\n",
    "\timport pandas as pd\n",
    "\ti = []; l = []; s = []# Initialise empty lists for storing extracted info\n",
    "\tfor item in d[\"results\"][\"bindings\"]:\n",
    "\t\tj = item['item']['value'].split('/')[-1] # qid\n",
    "\t\tm = item['itemLabel']['value'].title() # longName\n",
    "\t\tt = m.replace(' ', '').replace(')', '').replace('(', \\\n",
    "\t    '').replace('-', '').replace('.', '').replace(',', \\\n",
    "\t    '').replace(\"'\", '').replace(\"'\", '').lower() #shortName\n",
    "\t\ti.append(j); l.append(m); s.append(t)\n",
    "\t    #print(j, m, t)\n",
    "\treturn pd.DataFrame({'name': s, 'ids': i, 'longName': l})# Create a new DataFrame with the resulting lists above fs-firestore\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "NO\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "#docs = db.collection(u'dictionary').where(u'origin', u'==', u'manual').stream()\n",
    "#name = 'commds'\n",
    "doccs = db.collection(u'sparql_tst').stream()\n",
    "#doccs.to_dict().get(name)\n",
    "for doc in doccs:\n",
    "    x=u'{}'.format(doc.to_dict())\n",
    "    \n",
    "    if 'commds' in x:\n",
    "        continue\n",
    "    print('NO')\n",
    "print('no')\n",
    "    #print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Add Surgical procedures with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved!\n",
      "Beginning term addition...\n",
      "Done adding 236 terms!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "# IMPORT_NEEDED_PKGs\n",
    "import uuid, time, firebase_admin, pandas as pd, os, requests, sys\n",
    "from firebase_admin import firestore, credentials\n",
    "from bs4 import BeautifulSoup\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "'''\n",
    "# ACCESS_SPARQL-Wd_ENDPOINT\n",
    "# This section will require a regular SPARQL query for the data of interest\n",
    "\n",
    "#from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "#query = '''\n",
    "#SELECT ?item ?itemLabel {\n",
    "#  ?item wdt:P31?/wdt:P279* wd:Q600236\n",
    "#  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "#}\n",
    "#ORDER BY ?itemLabel\n",
    "'''\n",
    "\n",
    "\n",
    "def get_results(x, y):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(x, agent=user_agent)\n",
    "    sparql.setQuery(y)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "# CONVERT_TO_FLASHPUB_DATA_MODEL\n",
    "# This section process the SPARQL output to flashPub specifications\n",
    "#def to_fp_data_model(d):\n",
    "def to_fp_data_model(d):    \n",
    "    i = []; l = []; s = []; u = []# Initialise empty lists for storing extracted info\n",
    "    for item in d[\"results\"][\"bindings\"]:\n",
    "        v = BeautifulSoup(requests.get(item['item']['value'].replace('entity', \\\n",
    "        'wiki')).text).find('span', class_='wikibase-descriptionview-text').text.capitalize()\n",
    "        # Scrapes the desription field from term wed page, or whatever text will be in that filed (eg. 'No description')\n",
    "        j = item['item']['value'].split('/')[-1] # Gets the qid from term hyperlink\n",
    "        m = item['itemLabel']['value'].title() # Gets longName from itemLabel field and capitalises it\n",
    "        t = m.replace(' ', '').replace(')', '').replace('(', \\\n",
    "        '').replace('-', '').replace('.', '').replace(',', \\\n",
    "        '').replace(\"'\", '').replace(\"'\", '').lower() # Removes meta-characters and adjust cases from the itemLabel field\n",
    "        i.append(j); l.append(m); s.append(t); u.append(v) # Adds new values to growing lists ealier initialised\n",
    "        #print(j, m, t)\n",
    "    return pd.DataFrame({'name': s, 'ids': i, 'longName': l, 'description': u})\n",
    "    # Create a DataFrame of all term data needed with the resulting lists above fs-firestore\n",
    "\n",
    "df = to_fp_data_model(results)# Creates a variable of the resulting DataFrame from above for firestore entry\n",
    "\n",
    "df.to_csv('SurgicalDataFrame.csv')\n",
    "'''\n",
    "print('DataFrame saved!')\n",
    "# CONFIG_FIREBASE\n",
    "cred = credentials.Certificate(\"...firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)# Rememebr not to push your cred file, add to git ignore\n",
    "db = firestore.client()\n",
    "\n",
    "OrcId = '0000-0003-0994-2558'\n",
    "entryCount = 0# Initialise a count var to monitor number of entries pushed to firestore\n",
    "print('Beginning term addition...')\n",
    "# FIRESTORE_TERM_ADDITION\n",
    "for (name, qID, longName, des) in zip(df.name, df.ids, df.longName, df.description):\n",
    "    '''\n",
    "    docs = db.collection(u'sparql_tst').where(u'name', u'==', name).stream()# Retrieves an item from the firestore collection to \n",
    "    # CHECK_IF_TERM_EXITS\n",
    "    x = None\n",
    "    for doc in docs:\n",
    "        x = doc.getData('name')#'u{}'.format(doc.to_dict())\n",
    "    if name in x:\n",
    "        continue# Break for loop if the term already exits in the db, otherwise new term is added\n",
    "    '''\n",
    "    # UNIQUE_TERM_ID (UUID-4)\n",
    "    termId = str(uuid.uuid4())\n",
    "\n",
    "    # TIMESTAMP\n",
    "    pythonTime = datetime.now()\n",
    "    currentTime = time.mktime(pythonTime.timetuple()) * 1000\n",
    "\n",
    "    # DATA\n",
    "    termData = {\n",
    "        u'name': name,\n",
    "        u'longName': longName,\n",
    "        u'description': des, \n",
    "        u'ancestors': [# BE SURE TO GET THE RIGHT ANCESTORS\n",
    "            u'9f39c304-9c67-4251-83d9-86f7837c0135', \n",
    "            u'adabe023-24ec-4a02-892f-8cfdcbc43f30', \n",
    "            u'1e8bd2b5-b762-41cd-a79d-d04af88bbbde',\n",
    "            termId #Make term id self-reference as ancestor\n",
    "        ], \n",
    "        u'props': None, \n",
    "        u'author': {\n",
    "            u'affiliation': u'@flashpub.io', \n",
    "            u'orcid': OrcId\n",
    "        }, \n",
    "        u'type': u'thing', \n",
    "        u'origin': {\n",
    "            u'url': u'https://www.wikidata.org/', \n",
    "            u'qid': qID,\n",
    "            u'tag': u'ssurgicalprocedures'\n",
    "        },\n",
    "        u'id': termId, \n",
    "        u'isCommunity': False, \n",
    "        u'metrics': {\n",
    "            u'authorCount': 0,\n",
    "            u'pubCount': 0,\n",
    "            u'dateAdded': currentTime,\n",
    "            u'dateModified': currentTime,\n",
    "            \n",
    "        }\n",
    "    }\n",
    "\n",
    "    # SUBMIT\n",
    "    db.collection('dictionary').document(termId).set(termData)\n",
    "    entryCount+=1\n",
    "    # MONITOR_TERM_ADDITIONS\n",
    "duration = datetime.now() - start\n",
    "# LOG_FILE\n",
    "add_term_log = open('add_term_log.txt', 'a') # Open log file for appending\n",
    "print('A total of', entryCount, ' items have been added to the dictionary in firestore dev \\\n",
    "on', datetime.today().strftime('%Y-%m-%d-%H:%M:%S'), 'in time', duration, file = add_term_log)# Add a record into the log file\n",
    "add_term_log.close() #Close log file\n",
    "print('Done adding %s terms!' % entryCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('SurgicalDataFrame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name        ids  \\\n",
      "0                      bannayanrileyruvalcabasyndrome    Q474254   \n",
      "1                                    phaceassociation   Q3377927   \n",
      "2                                           pinealoma   Q1047551   \n",
      "3                                     proteussyndrome    Q281115   \n",
      "4                                sturge–webersyndrome   Q1886238   \n",
      "5                       atypicalteratoidrhabdoidtumor    Q631904   \n",
      "6                                    brainastrocytoma  Q55789755   \n",
      "7                                      braingerminoma  Q18555001   \n",
      "8                                         brainglioma  Q18553667   \n",
      "9                                     brainmeningioma  Q18553665   \n",
      "10                                       brainsarcoma  Q18555002   \n",
      "11                              cerebralneuroblastoma  Q18556218   \n",
      "12    childhoodcentralnervoussystemmixedgermcelltumor  Q18557623   \n",
      "13                        childhoodgermcellbraintumor  Q18557585   \n",
      "14           extragonadalnonseminomatousgermcelltumor  Q18556934   \n",
      "15                                 gliomatosiscerebri   Q1531482   \n",
      "16               hereditaryneurocutaneousmalformation  Q55780322   \n",
      "17                               hypothalamicneoplasm  Q18556009   \n",
      "18                               infratentorialcancer  Q18556448   \n",
      "19  malignantneoplasmofcerebrumexceptlobesandventr...  Q19001372   \n",
      "20                             olfactorynerveneoplasm  Q18556013   \n",
      "21                 pediatriccnsembryonalcellcarcinoma  Q18557522   \n",
      "22                               pilocyticastrocytoma   Q2095252   \n",
      "23                               supratentorialcancer  Q18554868   \n",
      "\n",
      "                                             longName  \\\n",
      "0                   Bannayan-Riley-Ruvalcaba Syndrome   \n",
      "1                                   Phace Association   \n",
      "2                                           Pinealoma   \n",
      "3                                    Proteus Syndrome   \n",
      "4                               Sturge–Weber Syndrome   \n",
      "5                    Atypical Teratoid Rhabdoid Tumor   \n",
      "6                                   Brain Astrocytoma   \n",
      "7                                     Brain Germinoma   \n",
      "8                                        Brain Glioma   \n",
      "9                                    Brain Meningioma   \n",
      "10                                      Brain Sarcoma   \n",
      "11                             Cerebral Neuroblastoma   \n",
      "12  Childhood Central Nervous System Mixed Germ Ce...   \n",
      "13                    Childhood Germ Cell Brain Tumor   \n",
      "14       Extragonadal Nonseminomatous Germ Cell Tumor   \n",
      "15                                Gliomatosis Cerebri   \n",
      "16             Hereditary Neurocutaneous Malformation   \n",
      "17                              Hypothalamic Neoplasm   \n",
      "18                              Infratentorial Cancer   \n",
      "19  Malignant Neoplasm Of Cerebrum Except Lobes An...   \n",
      "20                           Olfactory Nerve Neoplasm   \n",
      "21             Pediatric Cns Embryonal Cell Carcinoma   \n",
      "22                              Pilocytic Astrocytoma   \n",
      "23                              Supratentorial Cancer   \n",
      "\n",
      "                                          description  \n",
      "0   A rare overgrowth syndrome and hamartomatous d...  \n",
      "1   Cutaneous condition characterized by multiple ...  \n",
      "2   Endocrine gland located in the pineal gland lo...  \n",
      "3   A human disease characterized by an overgrowth...  \n",
      "4   A rare congenital neurological and skin disord...  \n",
      "5   Brain cancer that is usually located in the br...  \n",
      "6   Astrocytoma (excluding glioblastoma) that invo...  \n",
      "7                                       Human disease  \n",
      "8   Brain cancer that has material basis in glial ...  \n",
      "9                                       Human disease  \n",
      "10                                      Human disease  \n",
      "11                                      Human disease  \n",
      "12                                      Human disease  \n",
      "13                                      Human disease  \n",
      "14  Extragonadal germ cell cancer that are located...  \n",
      "15                           Rare primary brain tumor  \n",
      "16                             No description defined  \n",
      "17                                      Human disease  \n",
      "18  Brain cancer that is located in the infratento...  \n",
      "19                                      Human disease  \n",
      "20                                      Human disease  \n",
      "21                                      Human disease  \n",
      "22  Astrocytoma that is characterized by cells tha...  \n",
      "23  Brain cancer that is located in the supratento...  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "# IMPORT_NEEDED_PKGs\n",
    "import uuid, time, firebase_admin, pandas as pd, os, requests, sys\n",
    "from firebase_admin import firestore, credentials\n",
    "from bs4 import BeautifulSoup\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# ACCESS_SPARQL-Wd_ENDPOINT\n",
    "# This section will require a regular SPARQL query for the data of interest\n",
    "\n",
    "#from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = '''\n",
    "SELECT ?item ?itemLabel #?cancer ?subclass #?symptomLabel  ?symptom\n",
    "WHERE\n",
    "{\n",
    "\t?item  wdt:P279  wd:Q18554460#wd:Q12078#(cancer) Q29512471(cancertypes)   #Q6608753(listofcancertypes)\n",
    "    #; wdt:P31 ?subclass\n",
    "\tSERVICE wikibase:label {  bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "ORDER BY ?itemLabel\n",
    "'''\n",
    "\n",
    "\n",
    "def get_results(x, y):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(x, agent=user_agent)\n",
    "    sparql.setQuery(y)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "# CONVERT_TO_FLASHPUB_DATA_MODEL\n",
    "# This section process the SPARQL output to flashPub specifications\n",
    "#def to_fp_data_model(d):\n",
    "def to_fp_data_model(d):    \n",
    "    i = []; l = []; s = []; u = []# Initialise empty lists for storing extracted info\n",
    "    for item in d[\"results\"][\"bindings\"]:\n",
    "        v = BeautifulSoup(requests.get(item['item']['value'].replace('entity', \\\n",
    "        'wiki')).text).find('span', class_='wikibase-descriptionview-text').text.capitalize()\n",
    "        # Scrapes the desription field from term wed page, or whatever text will be in that filed (eg. 'No description')\n",
    "        j = item['item']['value'].split('/')[-1] # Gets the qid from term hyperlink\n",
    "        m = item['itemLabel']['value'].title() # Gets longName from itemLabel field and capitalises it\n",
    "        t = m.replace(' ', '').replace(')', '').replace('(', \\\n",
    "        '').replace('-', '').replace('.', '').replace(',', \\\n",
    "        '').replace(\"'\", '').replace(\"'\", '').lower() # Removes meta-characters and adjust cases from the itemLabel field\n",
    "        i.append(j); l.append(m); s.append(t); u.append(v) # Adds new values to growing lists ealier initialised\n",
    "        #print(j, m, t)\n",
    "    return pd.DataFrame({'name': s, 'ids': i, 'longName': l, 'description': u})\n",
    "    # Create a DataFrame of all term data needed with the resulting lists above fs-firestore\n",
    "\n",
    "df = to_fp_data_model(results)# Creates a variable of the resulting DataFrame from above for firestore entry\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Web scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common virus that causes mild respiratory infections, but in rare cases potentially lethal.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "with open('WebScrapping.html') as html_file:\n",
    "    soup = BeautifulSoup(html_file, 'html')\n",
    "#print(soup.prettify())\n",
    "description = soup.find('span', class_='wikibase-descriptionview-text').text.lower()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "no description defined\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "qid_lnk = requests.get('https://www.wikidata.org/wiki/Q290805')\n",
    "print(qid_lnk.status_code)\n",
    "#print(qid_lnk.text)\n",
    "soup = BeautifulSoup(qid_lnk.text, 'lxml')\n",
    "description = soup.find('span', class_='wikibase-descriptionview-text').text.lower()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Request & Scrape (Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypertension occurring during pregnancy.\n"
     ]
    }
   ],
   "source": [
    "# RETRIEVE_TERM_DESCRIPTION\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "termPg = requests.get('https://www.wikidata.org/wiki/Q61335').text # Get web page and parse to html\n",
    "\n",
    "soup = BeautifulSoup(termPg) # Make a bs obj\n",
    "#print(soup.prettify())\n",
    "description = soup.find('span', class_='wikibase-descriptionview-text').text # Find target tag and use attribute to retrieve text\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Transfer docs from the \"ontology\" collection to \"dictionary\" collection\n",
    "## Add the AI id as ancestor to each doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Query' object has no attribute 'getData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-7f169aed41a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maiId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'a270f4ca-bd54-41de-98a4-c68a20fb1c33'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'sparl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'=='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Retrieve all docs with filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m '''\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Query' object has no attribute 'getData'"
     ]
    }
   ],
   "source": [
    "import firebase_admin, ast\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"...firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "aiId = u'a270f4ca-bd54-41de-98a4-c68a20fb1c33'\n",
    "\n",
    "docs = db.collection(u'ontology').stream() # Retrieve all docs with filter\n",
    "for doc in docs: # Iterate through the docs and collect the docs and dump them into a file\n",
    "    ont_docs = open('ont_docs.txt', 'a')\n",
    "    print(u'{}*{}'.format(doc.id, doc.to_dict()), file = ont_docs)#, doc.to_dict())) # Getting only the document IDs\n",
    "    ont_docs.close()\n",
    "ont_docs = open('ont_docs.txt', 'r+')\n",
    "#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\n",
    "for line in ont_docs: # Iterate through doc IDs deleting one item at a time\n",
    "    termId = line.split('*')[0]\n",
    "    termData = ast.literal_eval(line.split('*')[1])\n",
    "  \n",
    "    currentAncestors = termData['ancestors']\n",
    "    newAncestors = currentAncestors.append(aiId)\n",
    "    db.collection('dictionary').document(termId).set(termData)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Delete Surgical ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0! entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndict_docs = open('dict_docs.txt', 'r+')\\n#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\\nfor line in dict_docs: # Iterate through doc IDs deleting one item at a time\\n    print (line)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import firestore, credentials\n",
    "cred = credentials.Certificate(\"....json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred, name = 'flashpub-dev')\n",
    "db = firestore.client()\n",
    "\n",
    "count = 0\n",
    "docs = db.collection(u'dictionary').where(u'origin.tag', u'==', u'surgicalprocedures').stream() # Retrieve all docs with filter\n",
    "for doc in docs: # Iterate through the docs and collect the docs and dump them into a file\n",
    "    #dict_docs = open('dict_docs.txt', 'a')\n",
    "    print('Currently deleting...')\n",
    "    print(u'{}'.format(doc.id))#, doc.to_dict()), file = dict_docs)#, doc.to_dict())) # Getting only the document IDs\n",
    "    #dict_docs.close()\n",
    "    db.collection(u'dictionary').document(u'{}'.format(doc.id)).delete()\n",
    "    count+=1\n",
    "print('Deleted %s! entries' % count)\n",
    "'''\n",
    "dict_docs = open('dict_docs.txt', 'r+')\n",
    "#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\n",
    "for line in dict_docs: # Iterate through doc IDs deleting one item at a time\n",
    "    print (line)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Stream docs from dev and write to prod..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now adding terms to prod...\n",
      "Completed the addition of 236 terms to prod!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import firebase_admin, ast\n",
    "from firebase_admin import firestore, credentials\n",
    "from datetime import datetime\n",
    "'''\n",
    "cred = credentials.Certificate(\"...firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "firebase_admin.initialize_app(cred, name = 'flashpub-dev')\n",
    "db = firestore.client()\n",
    "\n",
    "print('Now streaming docs from dev...')\n",
    "docs = db.collection(u'dictionary').where(u'origin.tag', u'==', u'ssurgicalprocedures').stream() # Retrieve all docs with filter\n",
    "count1 = 0\n",
    "for doc in docs: # Iterate through the docs and collect the docs and dump them into a file\n",
    "    ssurg_docs = open('ssurg_docs.txt', 'a')\n",
    "    print(u'{}*{}'.format(doc.id, doc.to_dict()), file = ssurg_docs)#, doc.to_dict())) # Getting only the document IDs\n",
    "    ssurg_docs.close()\n",
    "    count1+=1\n",
    "print('Finished streaming %s terms from dev!' % count1)\n",
    "'''\n",
    "ssurg_docs = open('ssurg_docs.txt', 'r+')# Open file for reading\n",
    "\n",
    "# INITIALISE_PROD\n",
    "cred = credentials.Certificate(\"...firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\n",
    "count2 = 0\n",
    "print('Now adding terms to prod...')\n",
    "for line in ssurg_docs: # Iterate through doc IDs deleting one item at a time\n",
    "    termId = line.split('*')[0]\n",
    "    termData = ast.literal_eval(line.split('*')[1])\n",
    "    db.collection('dictionary').document(termId).set(termData)\n",
    "    count2+=1\n",
    "print('Completed the addition of %s terms to prod!' % count2)\n",
    "add_term_log = open('add_term_log.txt', 'a') # Open log file for appending\n",
    "print('A total of', count2, ' items have been added to the dictionary in firestore staging \\\n",
    "on', datetime.today().strftime('%Y-%m-%d-%H:%M:%S'), file = add_term_log)# Add a record into the log file\n",
    "add_term_log.close() #Close log file\n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Filter duplicates and Ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "    \n",
    "# Initialise data to lists.  \n",
    "data = [{'Geeks': 'dataframe', 'For': 'using', 'geeks': 5, 'DataFrame':100, 'Date': '2020-03-30'}, \n",
    "        {'Geeks':'Brian', 'For': \"Ochieng'\", 'geeks': 30, 'DataFrame':200, 'Date': '2020-03-29'}, \n",
    "        {'Geeks':'Semaj', 'For': 'Ognodo', 'geeks': 30, 'DataFrame':250, 'Date': '2020-03-27'},\n",
    "        {'Geeks':'Semaj', 'For': 'Ognodo', 'geeks': 30, 'DataFrame':300, 'Date': '2020-03-28'},\n",
    "        {'Geeks':'Ronny', 'For': 'Otiego', 'geeks': 30, 'DataFrame':400, 'Date': '2020-03-27'},\n",
    "        {'Geeks':'Dansu', 'For': 'D-man', 'geeks': 40, 'DataFrame':100, 'Date': '2020-03-26'}, \n",
    "        {'Geeks':'Brian', 'For': \"Ochieng'\", 'geeks': 30, 'DataFrame':100, 'Date': '2020-03-25'},\n",
    "        {'Geeks':'Byron', 'For': 'Oginga', 'geeks': 10, 'DataFrame':400, 'Date': '2020-03-24'}, \n",
    "        {'Geeks':'Brian', 'For': \"Ochieng'\", 'geeks': 30, 'DataFrame':50, 'Date': '2020-03-23'}]  \n",
    "    \n",
    "# Creates DataFrame.  \n",
    "df = pd.DataFrame(data)  \n",
    "    \n",
    "# Print the data  \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Geeks       For  geeks  DataFrame        Date\n",
      "0  Semaj    Ognodo     30        300  2020-03-28\n",
      "1  Semaj    Ognodo     30        250  2020-03-27\n",
      "2  Brian  Ochieng'     30        200  2020-03-29\n",
      "3  Brian  Ochieng'     30        100  2020-03-25\n",
      "4  Brian  Ochieng'     30         50  2020-03-23\n",
      "\n",
      "   Geeks       For  geeks  DataFrame        Date\n",
      "3  Semaj    Ognodo     30        300  2020-03-28\n",
      "2  Semaj    Ognodo     30        250  2020-03-27\n",
      "1  Brian  Ochieng'     30        200  2020-03-29\n",
      "6  Brian  Ochieng'     30        100  2020-03-25\n",
      "8  Brian  Ochieng'     30         50  2020-03-23\n"
     ]
    }
   ],
   "source": [
    "df_sb=df[df.duplicated(subset='Geeks',keep=False) == True].sort_values(by = ['Geeks','DataFrame', 'Date'], ascending=False)\n",
    "df_sb#.pivot_table(index=['Geeks'], aggfunc='size')\n",
    "reindx_df_sb = df_sb.reset_index(drop=True)\n",
    "print(reindx_df_sb)\n",
    "print()\n",
    "print(df_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Ochieng'</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>2020-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geeks       For  geeks  DataFrame        Date\n",
       "0  Semaj    Ognodo     30        300  2020-03-28\n",
       "1  Brian  Ochieng'     30        200  2020-03-29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, datetime\n",
    "from datetime import date\n",
    "Date = []\n",
    "for dt in df_sb['Date']:\n",
    "    year, month, day = map(int, dt.split('-'))\n",
    "    dt = datetime.date(year,month,day)\n",
    "    Date.append(dt)\n",
    "#print(df_sb)\n",
    "cp_reindx_df_sb = reindx_df_sb\n",
    "cp_reindx_df_sb['Date'] = Date\n",
    "#cp_df_sb.reset_index(inplace=True, drop=True)#reset dataframe index\n",
    "#cp_df_sb['Date'][0]\n",
    "f=cp_reindx_df_sb[date.today()-cp_reindx_df_sb['Date'] <=datetime.timedelta(days=10)]\n",
    "f.reset_index(inplace=True, drop=True)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Date</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>2020-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Ochieng'</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>2020-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Geeks       For  geeks  DataFrame        Date       dates\n",
       "0      3  Semaj    Ognodo     30        300  2020-03-28  2020-03-28\n",
       "1      1  Brian  Ochieng'     30        200  2020-03-29  2020-03-29"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy=df_sb[df_sb.duplicated(subset='Geeks', keep='first')==False]\n",
    "xy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-03-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geeks     For  geeks  DataFrame        Date\n",
       "3  Semaj  Ognodo     30        300  2020-03-28"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=df_sb[0:1]#.to_dict('records')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, Geeks             Semaj\n",
      "For              Ognodo\n",
      "geeks                30\n",
      "DataFrame           300\n",
      "Date         2020-03-28\n",
      "Name: 3, dtype: object)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows=df_sb.iterrows()\n",
    "counter=0\n",
    "\n",
    "for row in rows:\n",
    "    if counter == 0:\n",
    "        dff=pd.DataFrame(row)\n",
    "        counter+=1\n",
    "        row1=row\n",
    "        print(row1)\n",
    "        print()\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "locals() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-45256eb4faea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: locals() takes no arguments (1 given)"
     ]
    }
   ],
   "source": [
    "locals('row'+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sbG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f2aebb31fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_sbG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sbG' is not defined"
     ]
    }
   ],
   "source": [
    "z=df_sbG.append(df_sb[0:1], ignore_index=True)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geeks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brian</th>\n",
       "      <td>30.0</td>\n",
       "      <td>166.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geeks   DataFrame\n",
       "Geeks                   \n",
       "Brian   30.0  166.666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_sb.groupby('Geeks').mean()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geeks\n",
       "Brian    30.0\n",
       "Name: geeks, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(y[0:1]['geeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(y[0:1]['DataFrame']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>using</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ronny</td>\n",
       "      <td>Otiego</td>\n",
       "      <td>30</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dansu</td>\n",
       "      <td>D-man</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Byron</td>\n",
       "      <td>Oginga</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-03-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Geeks     For  geeks  DataFrame        Date\n",
       "0  dataframe   using      5        100  2020-03-30\n",
       "2      Semaj  Ognodo     30        300  2020-03-28\n",
       "3      Ronny  Otiego     30        400  2020-03-27\n",
       "4      Dansu   D-man     40        100  2020-03-26\n",
       "6      Byron  Oginga     10        400  2020-03-24"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sbG=df[df.duplicated(subset='Geeks',keep=False) == False]\n",
    "df_sbG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.66666666666666"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df_sb.mean()\n",
    "geeks = x['geeks']\n",
    "x['DataFrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>using</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronny</td>\n",
       "      <td>Otiego</td>\n",
       "      <td>30</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dansu</td>\n",
       "      <td>D-man</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Byron</td>\n",
       "      <td>Oginga</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "      <td>2020-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Ochieng'</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>2020-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Geeks       For  geeks  DataFrame        Date\n",
       "0  dataframe     using      5        100  2020-03-30\n",
       "1      Ronny    Otiego     30        400  2020-03-27\n",
       "2      Dansu     D-man     40        100  2020-03-26\n",
       "3      Byron    Oginga     10        400  2020-03-24\n",
       "4      Semaj    Ognodo     30        300  2020-03-28\n",
       "5      Brian  Ochieng'     30        200  2020-03-29"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def fp_unique_latest(x):\n",
    "    #df-dataFrame; unq-unique; dup-duplicate; srt-sorted; fnl-final\n",
    "    func takes df_campaign_data and converts it to a pandas DataFrame, looks for dup based on the 'id' \n",
    "    (lat/long) and sort them first by 'id' and a second by 'dataData', takes the latest entres of all dups, \n",
    "    append them to a df without dups and returns a list of dicts\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(x)\n",
    "'''\n",
    "df_unq=df[df.duplicated(subset='Geeks',keep=False) == False]\n",
    "df_dup=df[df.duplicated(subset='Geeks',keep=False) == True]\n",
    "df_dup_srt=df_dup.sort_values(by = ['Geeks', 'Date'], ascending=False)\n",
    "df_dup_srt_lts=df_dup_srt[df_dup_srt.duplicated(subset='Geeks', keep='first')==False]\n",
    "df_unq_fnl=df_unq.append(df_dup_srt_lts, ignore_index=True)\n",
    "df_unq_fnl\n",
    "#l= df_unq_fnl.to_dict('records')\n",
    "#l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>using</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ronny</td>\n",
       "      <td>Otiego</td>\n",
       "      <td>30</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dansu</td>\n",
       "      <td>D-man</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Byron</td>\n",
       "      <td>Oginga</td>\n",
       "      <td>10</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Geeks     For  geeks  DataFrame\n",
       "0  dataframe   using      5        100\n",
       "2      Semaj  Ognodo     30        300\n",
       "3      Ronny  Otiego     30        400\n",
       "4      Dansu   D-man     40        100\n",
       "6      Byron  Oginga     10        400"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sbF=df[df.duplicated(subset='Geeks',keep=False) == False]\n",
    "df_sbF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbF[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "      <th>DataFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Ochieng'</td>\n",
       "      <td>30.0</td>\n",
       "      <td>166.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Byron</td>\n",
       "      <td>Oginga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dansu</td>\n",
       "      <td>D-man</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ronny</td>\n",
       "      <td>Otiego</td>\n",
       "      <td>30.0</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semaj</td>\n",
       "      <td>Ognodo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>using</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Geeks       For  geeks   DataFrame\n",
       "0      Brian  Ochieng'   30.0  166.666667\n",
       "1      Byron    Oginga   10.0  400.000000\n",
       "2      Dansu     D-man   40.0  100.000000\n",
       "3      Ronny    Otiego   30.0  400.000000\n",
       "4      Semaj    Ognodo   30.0  300.000000\n",
       "5  dataframe     using    5.0  100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grp = df.groupby(['Geeks','For'], as_index=False).mean()\n",
    "df_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "6    False\n",
       "1     True\n",
       "5    False\n",
       "7     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_srtd = df.sort_values(by = 'Geeks', ascending=False).duplicated(keep=False)\n",
    "df_srtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geeks</th>\n",
       "      <th>For</th>\n",
       "      <th>geeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ronny</td>\n",
       "      <td>c</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataframe</td>\n",
       "      <td>using</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Geeks    For  geeks\n",
       "3         20     30     40\n",
       "1         10     20     30\n",
       "2      Ronny      c     30\n",
       "4         10     20     30\n",
       "5          5     10     10\n",
       "0  dataframe  using      5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'geeks', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type('2020-04-15'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter date:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 4, 3, 0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "date = parser.parse(input(\"Enter date: \"))\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Date difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUrray!\n"
     ]
    }
   ],
   "source": [
    "import time,datetime\n",
    "from datetime import date\n",
    "lastwk = datetime.date(2020,3,31)\n",
    "today = date.today()\n",
    "today\n",
    "diff = today - lastwk\n",
    "diff\n",
    "if diff == datetime.timedelta(days=6):\n",
    "    print('HUrray!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest unique data\n",
    "def fp_unique_latest(x):\n",
    "    #df-dataFrame; unq-unique; dup-duplicate; srt-sorted; fnl-final\n",
    "    '''func takes df_campaign_data and converts it to a pandas DataFrame, looks for dup based on the 'id' \n",
    "    (lat/long) and sort them first by 'id' and a second by 'dataData', takes the latest entres of all dups, \n",
    "    append them to a df without dups and returns a list of dicts'''\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(x)\n",
    "    df_unq=df[df.duplicated(subset='id',keep=False) == False]\n",
    "    df_dup=df[df.duplicated(subset='id',keep=False) == True]\n",
    "    df_dup_srt=df_dup.sort_values(by = ['id', 'endorsementCount'], ascending=False)\n",
    "    df_dup_srt_lts=df_dup_srt[df_dup_srt.duplicated(subset='id', keep='first')==False]\n",
    "    df_unq_fnl=df_unq.append(df_dup_srt_lts, ignore_index=True)\n",
    "    return df_unq_fnl.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 4, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = '2020-04-06'\n",
    "year, month, day = map(int, dt.split('-'))\n",
    "date = datetime.date(year,month,day)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name is Ouso\n",
      "\n",
      "cp_name is Ouso\n",
      "\n",
      "cp_name 2 is Obado\n",
      "\n",
      "name 2 is Ouso\n"
     ]
    }
   ],
   "source": [
    "name = \"Ouso\"\n",
    "print('name is ' + name)\n",
    "print()\n",
    "cp_name = name\n",
    "print('cp_name is ' + cp_name)\n",
    "print()\n",
    "cp_name = \"Obado\"\n",
    "print('cp_name 2 is ' + cp_name)\n",
    "print()\n",
    "print('name 2 is ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":[{\"id\":397,\"wikiDataId\":\"Q1863\",\"type\":\"CITY\",\"city\":\"Andorra la Vella\",\"name\":\"Andorra la Vella\",\"country\":\"Andorra\",\"countryCode\":\"AD\",\"region\":\"Andorra la Vella\",\"regionCode\":\"07\",\"latitude\":42.5,\"longitude\":1.5},{\"id\":866,\"wikiDataId\":\"Q24554\",\"type\":\"CITY\",\"city\":\"Arinsal\",\"name\":\"Arinsal\",\"country\":\"Andorra\",\"countryCode\":\"AD\",\"region\":\"La Massana\",\"regionCode\":\"04\",\"latitude\":42.56666667,\"longitude\":1.48333333},{\"id\":408,\"wikiDataId\":\"Q24456\",\"type\":\"CITY\",\"city\":\"El Pas de la Casa\",\"name\":\"El Pas de la Casa\",\"country\":\"Andorra\",\"countryCode\":\"AD\",\"region\":\"Encamp\",\"regionCode\":\"03\",\"latitude\":42.54277,\"longitude\":1.73361},{\"id\":614,\"wikiDataId\":\"Q24413\",\"type\":\"CITY\",\"city\":\"El Tarter\",\"name\":\"El Tarter\",\"country\":\"Andorra\",\"countryCode\":\"AD\",\"region\":\"Canillo\",\"regionCode\":\"02\",\"latitude\":42.58333333,\"longitude\":1.65},{\"id\":497,\"wikiDataId\":\"Q989558\",\"type\":\"CITY\",\"city\":\"Encamp\",\"name\":\"Encamp\",\"country\":\"Andorra\",\"countryCode\":\"AD\",\"region\":\"Encamp\",\"regionCode\":\"03\",\"latitude\":42.51666667,\"longitude\":1.56666667}],\"links\":[{\"rel\":\"first\",\"href\":\"/v1/geo/cities?offset=0&limit=5\"},{\"rel\":\"next\",\"href\":\"/v1/geo/cities?offset=5&limit=5\"},{\"rel\":\"last\",\"href\":\"/v1/geo/cities?offset=266705&limit=5\"}],\"metadata\":{\"currentOffset\":0,\"totalCount\":266709}}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "url=\"https://wft-geo-db.p.rapidapi.com/v1/geo/cities\"\n",
    "\n",
    "headers= { 'x-rapidapi-host': 'wft-geo-db.p.rapidapi.com', \n",
    "          'x-rapidapi-key': '227367db63msh93937e4c26e4cf4p1c1509jsn7f9a54fdc8e1'\n",
    "         }\n",
    "response=requests.get(url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Get place based on cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('lat', '28.63576'),\n",
      "              ('lon', '77.22445'),\n",
      "              ('name', 'New Delhi'),\n",
      "              ('admin1', 'NCT'),\n",
      "              ('admin2', 'New Delhi'),\n",
      "              ('cc', 'IN')])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ncities = {'Nairobi' : [], 'New Dehlis' : []}\\ncities.keys()\\nx = 'Tanzania'\\ncities[x]=[]\\ncities.keys()\\ncities\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import reverse_geocoder as gr, pprint\n",
    "lat = 28.613939\n",
    "lon = 77.209023\n",
    "def reverseGeocode(x):\n",
    "    return gr.search(x)\n",
    "#x = (28.613939, 77.209023)\n",
    "\n",
    "results = reverseGeocode([lat, lon])\n",
    "#print(results)\n",
    "#print()\n",
    "pprint.pprint(results)\n",
    "#print()\n",
    "#results[0]['name']\n",
    "'''\n",
    "cities = {'Nairobi' : [], 'New Dehlis' : []}\n",
    "cities.keys()\n",
    "x = 'Tanzania'\n",
    "cities[x]=[]\n",
    "cities.keys()\n",
    "cities\n",
    "'''\n",
    "\n",
    "#results\n",
    "\n",
    "\n",
    "\n",
    "cityPubs = {}\n",
    "for pubid in pubids:\n",
    "    #get pub data\n",
    "    pub = db.collection(u'pubs').document(pubid).get().to_dict()\n",
    "    lat = pub[u'claim'][u'conditions'][0]['value']['value']['latitude']\n",
    "    lon = pub[u'claim'][u'conditions'][0]['value']['value']['logitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'author': 'Nathan S Jacobs',\n",
      "  'date': 1585201648936,\n",
      "  'fetchId': 'city-model-of-covid-19-spread_bf4d8811-6db1-4c63-bf6d-fba381bacb40',\n",
      "  'id': 'bf4d8811-6db1-4c63-bf6d-fba381bacb40',\n",
      "  'title': 'City model of COVID-19 Spread'}]\n",
      "\n",
      "https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_San_Diego&pubids=bf4d8811-6db1-4c63-bf6d-fba381bacb40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#docs = db.collection(u'dictionary').where(u'origin', u'==', u'api-python').stream() # Retrieve all docs with filter\\nfor claim in claims: # Iterate through the docs and collect the docs and dump them into a file\\n    dict_claims = open('dict_claims.txt', 'a')\\n    print(u'{}  {}'.format(claim.id, claim.to_dict()), file = dict_claims)#, doc.to_dict())) # Getting only the document IDs\\n    dict_claims.close()\\ndict_claims = open('dict_claims.txt', 'r+')\\n#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\\nfor line in dict_claims: # Iterate through doc IDs deleting one item at a time\\n    print (line)\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORT\n",
    "import os, datetime, time, firebase_admin, pprint\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# INIT FIREBASE\n",
    "cred = credentials.Certificate(\"...firebase-o.json\") # SET PROD / STAGING / DEV BY COPY/PASTING CREDS INTO SPECIFIED FILE\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "# Timestamp\n",
    "pythonTime = datetime.datetime.now();\n",
    "currentTime = time.mktime(pythonTime.timetuple()) * 1000;\n",
    "\n",
    "#set claim id\n",
    "#claimid = u\"cd14183f-bb8f-415f-956f-2c83894cfc9f\" #DEV\n",
    "\n",
    "#get list of pubs\n",
    "claims = db.collection(u'claims').where(\"claimItems.firstItem.name\", \"==\", \"covid19spread\").stream()\n",
    "cityPubs = {}\n",
    "for claim in claims:\n",
    "    linkedPubIds = claim.to_dict()[u'linkedPubIds']\n",
    "    for linkedPubId in linkedPubIds:\n",
    "        pub = db.collection(u'pubs').document(linkedPubId).get().to_dict()\n",
    "        #print(pub['title'])\n",
    "        cond = pub[u'claim'][u'conditions']\n",
    "        if len(cond) != 0:\n",
    "            try:\n",
    "                data = cond[0]\n",
    "                city = data['value']['value']['city']\n",
    "                #lat = data['value']['value']['latitude']\n",
    "                #lon = data['value']['value']['longitude']\n",
    "                fetchId = pub['metadata']['fetchId']\n",
    "                iD = linkedPubId\n",
    "                title = pub['title']\n",
    "                date = pub['metadata']['datePublished']\n",
    "                author = pub['author']['name']\n",
    "                pubData = {\n",
    "                'fetchId': fetchId,\n",
    "                'id': iD,\n",
    "                'title': title,\n",
    "                'date': date,\n",
    "                'author': author\n",
    "                }\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        #cdnts = [lat, lon]\n",
    "        #print(city, lat, lon, pubId)\n",
    "        \n",
    "        \n",
    "            \n",
    "        if city in cityPubs.keys():\n",
    "            cityPubs[city].append(pubData)\n",
    "        else:\n",
    "            cityPubs[city] = [pubData]\n",
    "        \n",
    "        for key in cityPubs.keys():\n",
    "            cityIds = ''# Init empty string for ids for all pubs for the city\n",
    "            cityPubUrl = str('https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_{}&pubids='.format( key.replace(' ', '_')))# Base url for each city\n",
    "            count = len(cityPubs[key])# Init a count to control the addition of commas\n",
    "            for cityPub in cityPubs[key]:# Iter through every pub in the list of dicts containing pubs as dicts\n",
    "                 cityIds += cityPub['id']# Concatenate all ids of pubs from a city\n",
    "                 while count != 1:# controls for addition of the comma\n",
    "                     cityIds += ','# Comma added only if the pub is not reached\n",
    "                     count -= 1\n",
    "            cityPubUrl += cityIds# Concatenate base url with the comma-separated ids\n",
    "        cityPubsArray = cityPubs[city]\n",
    "pprint.pprint(cityPubsArray)\n",
    "\n",
    "print()            \n",
    "print(cityPubUrl)\n",
    "'''                \n",
    "        # SUBMIT\n",
    "            cityPubArray = cityPubs[key]\n",
    "            try:\n",
    "                db.collection('campaigns_tst').document('Outbreak-COVID-19-city').collection('campaignData').where('city' '==' key).update({\n",
    "                u'pubArray': cityPubArray,\n",
    "                u'pubURL': cityPubUrl\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "'''\n",
    "'''\n",
    "for key in cityPubs.keys():\n",
    "    cityIds = ''\n",
    "    cityPubUrl = str('https://outbreak.flashpub.io/publist?title=COVID-\\\n",
    "    19_Publications_for_{}&pubids='.format( key.replace(' ', '_')))\n",
    "    count = len(city[keys])\n",
    "    for cityPub in cityPubs[key]:\n",
    "         cityIds = cityIds + cityPub['id']\n",
    "         while count != 0:\n",
    "             cityIds += ','\n",
    "             count -= 1\n",
    "    cityPubUrl += cityIds\n",
    "    cityPubs[key].append({'cityPubUrl': cityPubUrl})\n",
    "    \n",
    "pprint.pprint(cityPubs)\n",
    "'''     \n",
    "'''db.collection('campaigns_tst').document('Outbreak-COVID-19-city').update({\n",
    "    u'campaignData':cityPubs,\n",
    "    u'updatedOn':currentTime\n",
    "})'''\n",
    "\n",
    "                       \n",
    "            \n",
    "'''\n",
    "        try:\n",
    "            lat = pub[u'claim'][u'conditions'][0]['value']['value']['latitude']#getData('latitude')\n",
    "        except:\n",
    "            print('Empty list')\n",
    "'''\n",
    "        \n",
    "        #print('Processing next pub in claim linked pubs...')\n",
    "    #print('Processing next claim...')\n",
    "#pubids = claim[u'linkedPubIds']\n",
    "#pubids\n",
    "'''https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_San_Diego&pubids=02ecb48b-3934-4ea7-ad26-107a10922498'''\n",
    "\n",
    "'''\n",
    "#docs = db.collection(u'dictionary').where(u'origin', u'==', u'api-python').stream() # Retrieve all docs with filter\n",
    "for claim in claims: # Iterate through the docs and collect the docs and dump them into a file\n",
    "    dict_claims = open('dict_claims.txt', 'a')\n",
    "    print(u'{}  {}'.format(claim.id, claim.to_dict()), file = dict_claims)#, doc.to_dict())) # Getting only the document IDs\n",
    "    dict_claims.close()\n",
    "dict_claims = open('dict_claims.txt', 'r+')\n",
    "#dict_docs.truncate(0)# If you want to clear file content, you will uncomment this line\n",
    "for line in dict_claims: # Iterate through doc IDs deleting one item at a time\n",
    "    print (line)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_San_Diego&pubids=bf4d8811-6db1-4c63-bf6d-fba381bacb40\n"
     ]
    }
   ],
   "source": [
    "cityPubs = {'San Diego': [{'author': 'Nathan S Jacobs',\n",
    "                'date': 1585201648936,\n",
    "                'fetchId': 'city-model-of-covid-19-spread_bf4d8811-6db1-4c63-bf6d-fba381bacb40',\n",
    "                'id': 'bf4d8811-6db1-4c63-bf6d-fba381bacb40',\n",
    "                'title': 'City model of COVID-19 Spread'}]}\n",
    "for key in cityPubs.keys():\n",
    "    cityIds = ''# Init empty string for ids for all pubs for the city\n",
    "    cityPubUrl = str('https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_{}&pubids='.format( key.replace(' ', '_')))# Base url for each city\n",
    "    count = len(cityPubs[key])# Init a count to control the addition of commas\n",
    "    for cityPub in cityPubs[key]:# Iter through every pub in the list of dicts containing pubs as dicts\n",
    "         cityIds += cityPub['id']# Concatenate all ids of pubs from a city\n",
    "         while count != 1:# controls for addition of the comma\n",
    "             cityIds += ','# Comma added only if the pub is not reached\n",
    "             count -= 1\n",
    "    cityPubUrl += cityIds# Concatenate base url with the comma-separated ids\n",
    "    print()\n",
    "    print(cityPubUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DocumentSnapshot' object has no attribute 'getData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-3ca6379de688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'campaigns_tst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outbreak-COVID-19-city'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'campaignData'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'001f146f-07c6-4417-85ab-9e06d6985154'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to_dict()#.where('city', '==', u'Hendry').stream()#.getDocument()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DocumentSnapshot' object has no attribute 'getData'"
     ]
    }
   ],
   "source": [
    "v=db.collection('campaigns_tst').document('Outbreak-COVID-19-city').collection('campaignData').document('001f146f-07c6-4417-85ab-9e06d6985154').get()#.to_dict()#.where('city', '==', u'Hendry').stream()#.getDocument()\n",
    "print (v.getData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'San Diego', 'latitude': 27.7625, 'longitude': -98.2389, 'state': 'CA'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "l = [{'id': 'OiPiN5qYx', 'type': 'city', 'value': {'value': {'state': 'CA', 'longitude': -98.2389, \n",
    "    'latitude': 27.7625, 'city': 'San Diego'}, 'label': 'San Diego, CA'}, 'name': 'city'}, \n",
    "     {'id': 'ZmtxYkTV4', 'type': 'date', 'value': '2020-03-25', 'name': 'dataDate'}, \n",
    "     {'id': 'fse-6u-G7', 'type': 'number', 'value': '149', 'name': 'hospitilizationCount'}, \n",
    "     {'type': 'boolean', 'value': 'true', 'name': 'patientCountIncreasing', 'id': 'HPuakPfZS'}, \n",
    "     {'name': 'hospitalBedCount', 'value': '13000', 'id': 'OwQc8xs9Q', 'type': 'number'}, \n",
    "     {'id': 'kKnFkTgpI', 'type': 'number', 'value': '300', 'name': 'hospitalVentilatorCount'}, \n",
    "     {'value': '2020-04-21', 'name': 'tippingPointDate', 'id': '87CAshEaC', 'type': 'date'}, \n",
    "     {'id': 'GLl2kmbt2', 'type': 'number', 'name': 'tippingPointDateConfidenceDays', 'value': '15'}]\n",
    "l_dict = l[0]\n",
    "pprint.pprint(l_dict['value']['value'])\n",
    "#len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nairobi': [27.7625, -98.2389], 'New Dehlis': []}\n",
      "\n",
      "{'Nairobi': [27.7625, -98.2389, [27.7625, -98.2389]], 'New Dehlis': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"cities.keys()\\nx = 'Tanzania'\\ncities[x]=[]\\ncities.keys()\\ncities\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = {'Nairobi' : [27.7625, -98.2389], 'New Dehlis' : []}\n",
    "print(cities)\n",
    "print()\n",
    "pubData = [lat, lon]\n",
    "cities['Nairobi'].append(pubData)\n",
    "print(cities)\n",
    "\n",
    "'''cities.keys()\n",
    "x = 'Tanzania'\n",
    "cities[x]=[]\n",
    "cities.keys()\n",
    "cities'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://outbreak.flashpub.io/publist?title=COVID-19_Publications_for_San_Diego&pubids=bf4d8811-6db1-4c63-bf6d-fba381bacb40'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubUrl = str('https://outbreak.flashpub.io/publist?title=\\\n",
    "COVID-19_Publications_for_{}&pubids={}'.format( city.replace(' ', '_'), pubId))\n",
    "pubUrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-17 08:55:09.649825\n",
      "\n",
      "time.struct_time(tm_year=2020, tm_mon=4, tm_mday=17, tm_hour=8, tm_min=55, tm_sec=9, tm_wday=4, tm_yday=108, tm_isdst=-1)\n",
      "\n",
      "1587102909.0\n",
      "\n",
      "1587102909000.0\n"
     ]
    }
   ],
   "source": [
    "import datetime, time \n",
    "pythonTime = datetime.datetime.now()\n",
    "currentTime = time.mktime(pythonTime.timetuple()) * 1000\n",
    "print(pythonTime)\n",
    "print()\n",
    "print(pythonTime.timetuple())\n",
    "print()\n",
    "print(time.mktime(pythonTime.timetuple()))\n",
    "print()\n",
    "print(currentTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OusoOuso'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = (1,'2')\n",
    "type(m)\n",
    "\n",
    "m[1]\n",
    "\n",
    "n = [1,2,3,4,5]\n",
    "print(str(n))\n",
    "l = 'Ouso'\n",
    "l+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': [1, 2, 3, 4], 'two': [5, 6, 7, 8, 9]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = {'one':[1, 2, 3, 4], 'two':[5,6,7,8]}\n",
    "t['two'].append(9)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.collection('campaigns_tst').document('Outbreak-COVID-19-city').collection('campaignData').where('city' '==' key).update({\n",
    "                u'pubArray': cityPubArray,\n",
    "                u'pubURL': cityPubUrl\n",
    "                })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
